{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "def get_dataset():\n",
    "    return datasets.FashionMNIST(\n",
    "        root=\"/tmp/data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = self.flatten(inputs)\n",
    "        logits = self.linear_relu_stack(inputs)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define single-worker PyTorch training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func():\n",
    "    num_epochs = 3\n",
    "    batch_size = 64\n",
    "\n",
    "    dataset = get_dataset()\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    model = NeuralNetwork()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(inputs)\n",
    "            loss = criterion(pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"epoch: {epoch}, loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /tmp/data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:15<00:00, 1657025.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/FashionMNIST/raw/train-images-idx3-ubyte.gz to /tmp/data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /tmp/data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 597431.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /tmp/data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /tmp/data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:01<00:00, 2551066.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /tmp/data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /tmp/data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 14252328.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/data/FashionMNIST/raw\n",
      "\n",
      "epoch: 0, loss: 0.9412856101989746\n",
      "epoch: 1, loss: 0.7699680328369141\n",
      "epoch: 2, loss: 0.7065638303756714\n"
     ]
    }
   ],
   "source": [
    "train_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert this to a distributed multi-worker training function\n",
    "Use the ray.train.torch.prepare_model and ray.train.torch.prepare_data_loader utility functions to set up your model and data for distributed training. This automatically wraps the model with DistributedDataParallel and places it on the right device, and adds DistributedSampler to the DataLoaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray.train.torch\n",
    "\n",
    "def train_func_distributed():\n",
    "    num_epochs = 3\n",
    "    batch_size = 64\n",
    "\n",
    "    dataset = get_dataset()\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    dataloader = ray.train.torch.prepare_data_loader(dataloader)\n",
    "\n",
    "    model = NeuralNetwork()\n",
    "    model = ray.train.torch.prepare_model(model)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if ray.train.get_context().get_world_size() > 1:\n",
    "            dataloader.sampler.set_epoch(epoch)\n",
    "\n",
    "        for inputs, labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(inputs)\n",
    "            loss = criterion(pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"epoch: {epoch}, loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate a TorchTrainer with 4 workers, and use it to run the new training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-02-27 14:49:32</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:46.34        </td></tr>\n",
       "<tr><td>Memory:      </td><td>6.5/7.7 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc                  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_ed52b_00000</td><td>TERMINATED</td><td>192.168.31.225:142601</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=142658)\u001b[0m Setting up process group for: env:// [rank=0, world_size=4]\n",
      "\u001b[36m(TorchTrainer pid=142601)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(TorchTrainer pid=142601)\u001b[0m - (ip=192.168.31.225, pid=142658) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(TorchTrainer pid=142601)\u001b[0m - (ip=192.168.31.225, pid=142659) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(TorchTrainer pid=142601)\u001b[0m - (ip=192.168.31.225, pid=142660) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(TorchTrainer pid=142601)\u001b[0m - (ip=192.168.31.225, pid=142661) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=142658)\u001b[0m Moving model to device: cpu\n",
      "\u001b[36m(RayTrainWorker pid=142658)\u001b[0m Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=142658)\u001b[0m epoch: 0, loss: 1.722748875617981\n",
      "\u001b[36m(RayTrainWorker pid=142658)\u001b[0m epoch: 1, loss: 0.8981984257698059\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=142658)\u001b[0m epoch: 2, loss: 0.7986962795257568\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "Trial TorchTrainer_ed52b_00000 completed. Last result: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 14:49:32,314\tINFO tune.py:1042 -- Total run time: 46.50 seconds (46.33 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "from ray.train.torch import TorchTrainer\n",
    "from ray.train import ScalingConfig\n",
    "# For GPU Training, set `use_gpu` to True.\n",
    "use_gpu = False\n",
    "trainer = TorchTrainer(\n",
    "    train_func_distributed,\n",
    "    scaling_config=ScalingConfig(num_workers=4, use_gpu=use_gpu))\n",
    "results = trainer.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
